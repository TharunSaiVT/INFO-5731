{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TharunSaiVT/INFO-5731/blob/main/V_T_Tharun_Sai_Exercise_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdRwkJBn70nX"
      },
      "source": [
        "# **INFO5731 In-class Exercise 4**\n",
        "\n",
        "**This exercise will provide a valuable learning experience in working with text data and extracting features using various topic modeling algorithms. Key concepts such as Latent Dirichlet Allocation (LDA), Latent Semantic Analysis (LSA), lda2vec, and BERTopic.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Please use the text corpus you collected in your last in-class-exercise for this exercise. Perform the following tasks***.\n",
        "\n",
        "**Expectations**:\n",
        "*   Students are expected to complete the exercise during lecture period to meet the active participation criteria of the course.\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "**Total points**: 40\n",
        "\n",
        "**Deadline**: This in-class exercise is due at the end of the day tomorrow, at 11:59 PM.\n",
        "\n",
        "**Late submissions will have a penalty of 10% of the marks for each day of late submission, and no requests will be answered. Manage your time accordingly.**\n"
      ],
      "metadata": {
        "id": "TU-pLW33lpcS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARqm7u6B70ne"
      },
      "source": [
        "## Question 1 (10 Points)\n",
        "\n",
        "**Generate K topics by using LDA, the number of topics K should be decided by the coherence score, then summarize what are the topics.**\n",
        "\n",
        "You may refer the code here: https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAZj4PHB70nf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "181ae9b4-e3a5-48f6-c979-2d2c8a4c6a35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal number of topics (K): 8\n",
            "Topic 1: 0.056*\"movie\" + 0.056*\"film\" + 0.056*\"love\" + 0.056*\"hilarious\" + 0.056*\"exceed\"\n",
            "Topic 2: 0.056*\"movie\" + 0.056*\"film\" + 0.056*\"exceed\" + 0.056*\"love\" + 0.056*\"boring\"\n",
            "Topic 3: 0.056*\"movie\" + 0.056*\"film\" + 0.056*\"boring\" + 0.056*\"exceed\" + 0.056*\"fantastic\"\n",
            "Topic 4: 0.180*\"expectation\" + 0.180*\"amazing\" + 0.180*\"exceed\" + 0.180*\"movie\" + 0.020*\"film\"\n",
            "Topic 5: 0.180*\"absolutely\" + 0.180*\"fantastic\" + 0.180*\"love\" + 0.180*\"movie\" + 0.020*\"film\"\n",
            "Topic 6: 0.056*\"movie\" + 0.056*\"film\" + 0.056*\"exceed\" + 0.056*\"love\" + 0.056*\"boring\"\n",
            "Topic 7: 0.180*\"disappointing\" + 0.180*\"find\" + 0.180*\"boring\" + 0.180*\"film\" + 0.020*\"movie\"\n",
            "Topic 8: 0.100*\"movie\" + 0.100*\"film\" + 0.100*\"weak\" + 0.100*\"subpar\" + 0.100*\"plot\"\n"
          ]
        }
      ],
      "source": [
        "# Write your code here\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.models import CoherenceModel\n",
        "import spacy\n",
        "\n",
        "# Sample data\n",
        "sample_data = [\n",
        "     \"The movie was fantastic, I absolutely loved it!\",\n",
        "    \"I found the film to be very disappointing and boring.\",\n",
        "    \"This movie exceeded my expectations, it was amazing!\",\n",
        "    \"The acting in this film was subpar and the plot was weak.\",\n",
        "    \"I couldn't stop laughing, this movie is hilarious!\"\n",
        "]\n",
        "\n",
        "# Step 1: Preprocess the text data\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def preprocess_text(texts):\n",
        "    processed_texts = []\n",
        "    for text in texts:\n",
        "        doc = nlp(text)\n",
        "        tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
        "        processed_texts.append(tokens)\n",
        "    return processed_texts\n",
        "\n",
        "processed_data = preprocess_text(sample_data)\n",
        "\n",
        "# Step 2: Create a dictionary and document-term matrix\n",
        "id2word = corpora.Dictionary(processed_data)\n",
        "corpus = [id2word.doc2bow(text) for text in processed_data]\n",
        "\n",
        "# Step 3: Determine the optimal number of topics (K) using coherence scores\n",
        "coherence_scores = []\n",
        "for k in range(2, 11):\n",
        "    lda_model = gensim.models.LdaModel(corpus=corpus, id2word=id2word, num_topics=k, random_state=100, update_every=1, chunksize=100, passes=10, alpha='auto', per_word_topics=True)\n",
        "    coherence_model = CoherenceModel(model=lda_model, texts=processed_data, dictionary=id2word, coherence='c_v')\n",
        "    coherence_score = coherence_model.get_coherence()\n",
        "    coherence_scores.append((k, coherence_score))\n",
        "\n",
        "# Select the K with the highest coherence score\n",
        "best_k, best_coherence = max(coherence_scores, key=lambda x: x[1])\n",
        "print(f\"Optimal number of topics (K): {best_k}\")\n",
        "\n",
        "# Step 5: Train the LDA model with the selected K\n",
        "lda_model = gensim.models.LdaModel(corpus=corpus, id2word=id2word, num_topics=best_k, random_state=100, update_every=1, chunksize=100, passes=10, alpha='auto', per_word_topics=True)\n",
        "\n",
        "# Step 6: Summarize the topics\n",
        "topics = lda_model.print_topics(num_topics=best_k, num_words=5)\n",
        "for topic in topics:\n",
        "    print(f\"Topic {topic[0] + 1}: {topic[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUjBE6C70nf"
      },
      "source": [
        "## Question 2 (10 Points)\n",
        "\n",
        "**Generate K topics by using LSA, the number of topics K should be decided by the coherence score, then summarize what are the topics.**\n",
        "\n",
        "You may refer the code here: https://www.datacamp.com/community/tutorials/discovering-hidden-topics-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoQX5s4O70nf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29d266d1-d614-474b-f002-97e82dbed961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 1: was, the, movie, it, this\n",
            "Topic 2: and, film, the, found, be\n"
          ]
        }
      ],
      "source": [
        "# Write your code here\n",
        "# Write your code here\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "sample_data = [\n",
        "     \"The movie was fantastic, I absolutely loved it!\",\n",
        "    \"I found the film to be very disappointing and boring.\",\n",
        "    \"This movie exceeded my expectations, it was amazing!\",\n",
        "    \"The acting in this film was subpar and the plot was weak.\",\n",
        "    \"I couldn't stop laughing, this movie is hilarious!\"\n",
        "]\n",
        "\n",
        "# Step 1: Preprocess the text data and create a TF-IDF matrix\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(sample_data)\n",
        "\n",
        "# Step 2: Determine the optimal number of topics (K) using LSA (you specify K)\n",
        "K = 2  # You can choose the number of topics\n",
        "lsa = TruncatedSVD(n_components=K)\n",
        "lsa_topic_matrix = lsa.fit_transform(tfidf_matrix)\n",
        "\n",
        "# Step 3: Summarize the topics\n",
        "terms = tfidf_vectorizer.get_feature_names_out()\n",
        "topic_keywords = []\n",
        "for i, topic in enumerate(lsa.components_):\n",
        "    top_terms = [terms[idx] for idx in topic.argsort()[-5:][::-1]]\n",
        "    topic_keywords.append(top_terms)\n",
        "    print(f\"Topic {i + 1}: {', '.join(top_terms)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oSK4soH70nf"
      },
      "source": [
        "## Question 3 (10 points):\n",
        "**Generate K topics by using lda2vec, the number of topics K should be decided by the coherence score, then summarize what are the topics.**\n",
        "\n",
        "You may refer the code here: https://nbviewer.org/github/cemoody/lda2vec/blob/master/examples/twenty_newsgroups/lda2vec/lda2vec.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CRuXfV570ng"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nZGAOwl70ng"
      },
      "source": [
        "## Question 4 (10 points):\n",
        "**Generate K topics by using BERTopic, the number of topics K should be decided by the coherence score, then summarize what are the topics.**\n",
        "\n",
        "You may refer the code here: https://colab.research.google.com/drive/1FieRA9fLdkQEGDIMYl0I3MCjSUKVF8C-?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4HoWK-i70ng"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra Question (5 Points)\n",
        "\n",
        "**Compare the results generated by the four topic modeling algorithms, which one is better? You should explain the reasons in details.**\n",
        "\n",
        "**This question will compensate for any points deducted in this exercise. Maximum marks for the exercise is 40 points.**"
      ],
      "metadata": {
        "id": "d89ODUx3jjJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here\n"
      ],
      "metadata": {
        "id": "OK34nZtojhmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Question"
      ],
      "metadata": {
        "id": "VEs-OoDEhTW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important: Reflective Feedback on this exercise**\n",
        "\n",
        "Please provide your thoughts and feedback on the exercises you completed in this assignment.\n",
        "\n",
        "Consider the following points in your response:\n",
        "\n",
        "**Learning Experience:** Describe your overall learning experience in working with text data and extracting features using various topic modeling algorithms. Did you understand these algorithms and did the implementations helped in grasping the nuances of feature extraction from text data.\n",
        "\n",
        "**Challenges Encountered:** Were there specific difficulties in completing this exercise?\n",
        "\n",
        "Relevance to Your Field of Study: How does this exercise relate to the field of NLP?\n",
        "\n",
        "**(Your submission will not be graded if this question is left unanswered)**\n",
        "\n"
      ],
      "metadata": {
        "id": "IUKC7suYhVl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "CAq0DZWAhU9m"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}