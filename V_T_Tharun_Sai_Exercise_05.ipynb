{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TharunSaiVT/INFO-5731/blob/main/V_T_Tharun_Sai_Exercise_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdRwkJBn70nX"
      },
      "source": [
        "# **INFO5731 In-class Exercise 5**\n",
        "\n",
        "**This exercise aims to provide a comprehensive learning experience in text analysis and machine learning techniques, focusing on both text classification and clustering tasks.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Please use the text corpus you collected in your last in-class-exercise for this exercise. Perform the following tasks***.\n",
        "\n",
        "**Expectations**:\n",
        "*   Students are expected to complete the exercise during lecture period to meet the active participation criteria of the course.\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "**Total points**: 40\n",
        "\n",
        "**Deadline**: This in-class exercise is due at the end of the day tomorrow, at 11:59 PM.\n",
        "\n",
        "**Late submissions will have a penalty of 10% of the marks for each day of late submission, and no requests will be answered. Manage your time accordingly.**\n"
      ],
      "metadata": {
        "id": "TU-pLW33lpcS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARqm7u6B70ne"
      },
      "source": [
        "## **Question 1 (20 Points)**\n",
        "\n",
        "The purpose of the question is to practice different machine learning algorithms for **text classification** as well as the performance evaluation. In addition, you are requried to conduct **10 fold cross validation** (https://scikit-learn.org/stable/modules/cross_validation.html) in the training.\n",
        "\n",
        "\n",
        "\n",
        "The dataset can be download from canvas. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Algorithms:**\n",
        "\n",
        "*   MultinominalNB\n",
        "*   SVM\n",
        "*   KNN\n",
        "*   Decision tree\n",
        "*   Random Forest\n",
        "*   XGBoost\n",
        "*   Word2Vec\n",
        "*   BERT\n",
        "\n",
        "**Evaluation measurement:**\n",
        "\n",
        "\n",
        "*   Accuracy\n",
        "*   Recall\n",
        "*   Precison\n",
        "*   F-1 score\n"
      ],
      "metadata": {
        "id": "loi8Sh7UE6ha"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VAZj4PHB70nf"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "# Write your code here\n",
        "#Write your code here.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWr5zsgNv1v1",
        "outputId": "76dd2b72-f08c-432d-de24-0b5de13fc78c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_sentiment_files(file1, file2):\n",
        "    try:\n",
        "        # Read file1 and file2\n",
        "        with open(file1, 'r', encoding='utf-8') as f1, open(file2, 'r', encoding='utf-8') as f2:\n",
        "            file1_lines = f1.readlines()\n",
        "            file2_lines = f2.readlines()\n",
        "\n",
        "        # Parse sentiment and review from file1\n",
        "        file1_sentiments = []\n",
        "        file1_reviews = []\n",
        "        for line in file1_lines:\n",
        "            sentiment, review = line.strip().split(' ', 1)\n",
        "            file1_sentiments.append(int(sentiment))\n",
        "            file1_reviews.append(review)\n",
        "\n",
        "        # Parse sentiment and review from file2\n",
        "        file2_sentiments = []\n",
        "        file2_reviews = []\n",
        "        for line in file2_lines:\n",
        "            sentiment, review = line.strip().split(' ', 1)\n",
        "            file2_sentiments.append(int(sentiment))\n",
        "            file2_reviews.append(review)\n",
        "\n",
        "        # Create DataFrames\n",
        "        df1 = pd.DataFrame({'sentiment': file1_sentiments, 'review': file1_reviews})\n",
        "        df2 = pd.DataFrame({'sentiment': file2_sentiments, 'review': file2_reviews})\n",
        "\n",
        "        return df1, df2\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading sentiment files: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Example usage:\n",
        "file1_path =  '/content/drive/My Drive/Colab Notebooks/stsa-train.txt'\n",
        "file2_path = '/content/drive/My Drive/Colab Notebooks/stsa-test.txt'\n",
        "\n",
        "train_df, test_df = load_sentiment_files(file1_path, file2_path)\n",
        "\n",
        "# Display the first few rows of each DataFrame\n",
        "if train_df is not None and test_df is not None:\n",
        "    print(\"Training Data:\")\n",
        "    print(train_df.head())\n",
        "\n",
        "    print(\"\\nTest Data:\")\n",
        "    print(test_df.head())\n",
        "else:\n",
        "    print(\"Error loading sentiment files.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7KgMCQYtfvk",
        "outputId": "34bc1f86-a25c-4467-9bfa-462971f68d14"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data:\n",
            "   sentiment                                             review\n",
            "0          1  a stirring , funny and finally transporting re...\n",
            "1          0  apparently reassembled from the cutting-room f...\n",
            "2          0  they presume their audience wo n't sit still f...\n",
            "3          1  this is a visually stunning rumination on love...\n",
            "4          1  jonathan parker 's bartleby should have been t...\n",
            "\n",
            "Test Data:\n",
            "   sentiment                                             review\n",
            "0          0     no movement , no yuks , not much of anything .\n",
            "1          0  a gob of drivel so sickly sweet , even the eag...\n",
            "2          0  gangs of new york is an unapologetic mess , wh...\n",
            "3          0  we never really feel involved with the story ,...\n",
            "4          1            this is one of polanski 's best films .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Split the training data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_df['review'], train_df['sentiment'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "zalL2kXHwATG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate classifier\n",
        "def train_and_evaluate_classifier(clf, name):\n",
        "    print(f'Evaluating {name}...')\n",
        "    # Use CountVectorizer to transform the text data into a matrix of word counts\n",
        "    vectorizer = CountVectorizer(stop_words='english')\n",
        "    X_train_vec = vectorizer.fit_transform(X_train)\n",
        "    X_val_vec = vectorizer.transform(X_val)\n",
        "\n",
        "    # Train the classifier using 10-fold cross-validation\n",
        "    scores = cross_val_score(clf, X_train_vec, y_train, cv=10)\n",
        "    print(f'Mean {name} cross-validation accuracy: {scores.mean()}')\n",
        "\n",
        "    # Fit the classifier to the entire training data and make predictions on the validation set\n",
        "    clf.fit(X_train_vec, y_train)\n",
        "    y_val_pred = clf.predict(X_val_vec)\n",
        "\n",
        "    # Evaluate the classifier on the validation set\n",
        "    accuracy = accuracy_score(y_val, y_val_pred)\n",
        "    precision = precision_score(y_val, y_val_pred)\n",
        "    recall = recall_score(y_val, y_val_pred)\n",
        "    f1 = f1_score(y_val, y_val_pred)\n",
        "    print(f'{name} validation accuracy: {accuracy}')\n",
        "    print(f'{name} validation precision: {precision}')\n",
        "    print(f'{name} validation recall: {recall}')\n",
        "    print(f'{name} validation F1 score: {f1}')\n",
        "    print('-'*40)"
      ],
      "metadata": {
        "id": "z4SOagCCwFTH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate the classifiers\n",
        "nb = MultinomialNB()\n",
        "train_and_evaluate_classifier(nb, 'MultinomialNB')\n",
        "\n",
        "svm = SVC(kernel='linear')\n",
        "train_and_evaluate_classifier(svm, 'SVM')\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "train_and_evaluate_classifier(knn, 'KNN')\n",
        "\n",
        "dt = DecisionTreeClassifier()\n",
        "train_and_evaluate_classifier(dt, 'Decision Tree')\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "train_and_evaluate_classifier(rf, 'Random Forest')\n",
        "\n",
        "xgb = XGBClassifier()\n",
        "train_and_evaluate_classifier(xgb, 'XGBoost')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zmrmf-UGwIiH",
        "outputId": "6609b752-e32c-4bf4-f214-1911833673be"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating MultinomialNB...\n",
            "Mean MultinomialNB cross-validation accuracy: 0.7720343906881401\n",
            "MultinomialNB validation accuracy: 0.7846820809248555\n",
            "MultinomialNB validation precision: 0.7539779681762546\n",
            "MultinomialNB validation recall: 0.8639551192145862\n",
            "MultinomialNB validation F1 score: 0.8052287581699346\n",
            "----------------------------------------\n",
            "Evaluating SVM...\n",
            "Mean SVM cross-validation accuracy: 0.7366396615768276\n",
            "SVM validation accuracy: 0.7622832369942196\n",
            "SVM validation precision: 0.7594594594594595\n",
            "SVM validation recall: 0.788218793828892\n",
            "SVM validation F1 score: 0.7735719201651756\n",
            "----------------------------------------\n",
            "Evaluating KNN...\n",
            "Mean KNN cross-validation accuracy: 0.5408314347079599\n",
            "KNN validation accuracy: 0.5614161849710982\n",
            "KNN validation precision: 0.5629453681710214\n",
            "KNN validation recall: 0.664796633941094\n",
            "KNN validation F1 score: 0.6096463022508037\n",
            "----------------------------------------\n",
            "Evaluating Decision Tree...\n",
            "Mean Decision Tree cross-validation accuracy: 0.6490289265639995\n",
            "Decision Tree validation accuracy: 0.6632947976878613\n",
            "Decision Tree validation precision: 0.6475507765830346\n",
            "Decision Tree validation recall: 0.7601683029453016\n",
            "Decision Tree validation F1 score: 0.6993548387096774\n",
            "----------------------------------------\n",
            "Evaluating Random Forest...\n",
            "Mean Random Forest cross-validation accuracy: 0.7090020955601544\n",
            "Random Forest validation accuracy: 0.7514450867052023\n",
            "Random Forest validation precision: 0.7274969173859432\n",
            "Random Forest validation recall: 0.8274894810659187\n",
            "Random Forest validation F1 score: 0.7742782152230971\n",
            "----------------------------------------\n",
            "Evaluating XGBoost...\n",
            "Mean XGBoost cross-validation accuracy: 0.6927500799707536\n",
            "XGBoost validation accuracy: 0.7167630057803468\n",
            "XGBoost validation precision: 0.6738894907908992\n",
            "XGBoost validation recall: 0.8723702664796634\n",
            "XGBoost validation F1 score: 0.7603911980440097\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KgxrJVrewL9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUjBE6C70nf"
      },
      "source": [
        "## **Question 2 (20 Points)**\n",
        "\n",
        "The purpose of the question is to practice different machine learning algorithms for **text clustering**.\n",
        "\n",
        "Please downlad the dataset by using the following link.  https://www.kaggle.com/PromptCloudHQ/amazon-reviews-unlocked-mobile-phones\n",
        "(You can also use different text data which you want)\n",
        "\n",
        "**Apply the listed clustering methods to the dataset:**\n",
        "*   K-means\n",
        "*   DBSCAN\n",
        "*   Hierarchical clustering\n",
        "*   Word2Vec\n",
        "*   BERT\n",
        "\n",
        "You can refer to of the codes from  the follwing link below.\n",
        "https://www.kaggle.com/karthik3890/text-clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoQX5s4O70nf"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "#Write your code here.\n",
        "\n",
        "reviews_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/stsa-train.txt')\n",
        "reviews_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In one paragraph, please compare the results of K-means, DBSCAN, Hierarchical clustering, Word2Vec, and BERT.**"
      ],
      "metadata": {
        "id": "tRijW2aLGONl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write your response here:**\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pIYCj5qyGfSL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Question"
      ],
      "metadata": {
        "id": "VEs-OoDEhTW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important: Reflective Feedback on this exercise**\n",
        "\n",
        "Please provide your thoughts and feedback on the exercises you completed in this assignment.\n",
        "\n",
        "\n",
        "**(Your submission will not be graded if this question is left unanswered)**\n",
        "\n"
      ],
      "metadata": {
        "id": "IUKC7suYhVl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "CAq0DZWAhU9m"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}